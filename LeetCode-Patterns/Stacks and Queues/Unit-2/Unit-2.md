
---

# ğŸ—ï¸ UNIT 2 â€” Monotonic Structures (Interview Filter Zone)

## ğŸ“¦ Modules Inside This Unit

- 2.1 â€” Monotonic Stack
    
- 2.2 â€” Monotonic Queue
    

---

## ğŸ“¦ Module 2.1 â€” Monotonic Stack

- 2.1.1 â€” Next Greater / Next Smaller Pattern â¬…ï¸ (Current)
    
- 2.1.2 â€” Range Influence & Span Computation
    

---

# ğŸ§© Submodule 2.1.1 â€” Next Greater / Next Smaller Pattern

This is where interviews start separating shallow stack users from real pattern thinkers.

---

## ğŸŸ¢ 1. Mental Model

Normal stack = LIFO constraint.

Monotonic stack = LIFO + ordered invariant.

You maintain the stack such that:

- Elements are always increasing  
    or
    
- Always decreasing
    

Depending on the problem.

The stack is no longer just storage.

It becomes a **filter that eliminates useless elements in one pass**.

---

## ğŸ”µ 2. Why This Exists

Brute force approach for "Next Greater Element":

For every element:

- Scan right
    
- Find first greater
    

Time: O(nÂ²)

Monotonic stack compresses that into:

O(n)

How?

By removing elements that can never be answers again.

---

## ğŸŸ£ 3. Core Building Blocks

Letâ€™s consider â€œNext Greater Elementâ€.

We process from left â†’ right.

We maintain a decreasing stack.

Invariant:

```
Stack elements are strictly decreasing from bottom to top.
```

Why decreasing?

Because when we see a new element `x`:

If `x` is greater than stack.top:

Then stack.top has found its next greater.

So we pop until invariant holds.

Each pop resolves one element permanently.

---

### Structural Behavior

Imagine array:

```
2 1 3
```

Step-by-step:

Push 2  
Stack: [2]

Push 1  
Stack: [2, 1]

See 3  
3 > 1 â†’ pop 1  
3 > 2 â†’ pop 2

Both resolved in one step.

Push 3  
Stack: [3]

Each element is pushed once and popped once.

Thatâ€™s why O(n).

---

## ğŸ§ª 4. How It Behaves in the Wild

### Normal Case

Each element:

- Enters stack once
    
- Leaves once
    

Total operations = 2n â†’ O(n)

---

### Failure Mode

If you forget invariant:

You fall back to nested loops.

---

### Important Variation

You can compute:

- Next Greater to right
    
- Next Greater to left
    
- Next Smaller
    
- Previous Smaller
    

By changing:

- Direction of traversal
    
- Comparison operator
    

Same skeleton.

---

## ğŸ› ï¸ 5. Real-World Usage Patterns

Monotonic stacks appear in:

- Daily Temperatures
    
- Stock Span
    
- Largest Rectangle in Histogram
    
- Trapping Rain Water
    
- Sum of Subarray Minimums
    

This is one of the highest ROI patterns in interviews.

---

Perfect.

Here is the **Ultimate Summary â€” Unit 2.1.1 Only**  
(Submodule: Next Greater / Next Smaller Pattern)

No spillover. Only this topic.

---

# ğŸ§  UNIT 2.1.1 â€” Monotonic Stack

## Pattern: Next Greater / Next Smaller

---

## 1ï¸âƒ£ What Problem It Solves

Brute force idea:

For every element:

- Scan right
    
- Find first greater (or smaller)
    

Time = O(nÂ²)

Monotonic stack compresses this to:

Time = O(n)

---

## 2ï¸âƒ£ Core Structural Invariant

For Next Greater (scan left â†’ right):

Maintain a **decreasing stack**.

Invariant:

```
Stack elements strictly decreasing from bottom â†’ top
```

Why?

Because if current element `x` is greater than stack.top:

Then stack.top has found its next greater.

So we pop it.

That pop is irreversible.

---

## 3ï¸âƒ£ Core Algorithm Skeleton

For each element `arr[i]`:

```
while stack not empty AND arr[i] > stack.top:
    pop stack.top (its answer is arr[i])

push arr[i]
```

Thatâ€™s the entire mechanism.

---

## 4ï¸âƒ£ Why It Is O(n)

Each element:

- Is pushed once.
    
- Is popped at most once.
    

Total stack operations:

```
pushes â‰¤ n
pops â‰¤ n
```

Total â‰¤ 2n â†’ O(n)

---

## 5ï¸âƒ£ Why Each Element Pops Only Once

Because:

- We scan strictly in one direction.
    
- Once popped, an element is permanently resolved.
    
- It never re-enters the stack.
    
- There is no mechanism to revisit earlier elements.
    

This is an **irreversible elimination process**.

No cycles.  
No resurrection.

---

## 6ï¸âƒ£ What Would Break O(n)

If:

- We re-scan the array.
    
- Or reinsert popped elements.
    
- Or revisit earlier indices.
    

Then elements could:

- Be pushed again.
    
- Be popped again.
    

Amortization collapses.

The single-pass + irreversibility guarantee is critical.

---

## 7ï¸âƒ£ Variations You Must Recognize

Same skeleton, only change:

- Traversal direction
    
- Comparison operator
    

You can compute:

- Next Greater Right
    
- Next Greater Left
    
- Next Smaller Right
    
- Previous Smaller
    
- Distance to next greater
    
- Indices instead of values
    

Itâ€™s the same invariant engine.

---

## 8ï¸âƒ£ Mental Compression Model

Monotonic stack =

- One-pass scan
    
- Stack enforces order
    
- New element eliminates weaker previous elements
    
- Each element dies once
    

Think of it as:

> Competitive elimination tournament.

When a stronger element appears, weaker ones lose permanently.

---

## 9ï¸âƒ£ What You Must Internalize

This is not a stack problem.

It is a:

> One-directional irreversible elimination system.

The stack is just the tool.

The real idea is:

- Eliminate useless elements immediately.
    
- Never revisit resolved states.
    

---

## ğŸ”Ÿ Where This Pattern Appears

- Daily Temperatures
    
- Next Greater Element I & II
    
- Stock Span
    
- Largest Rectangle in Histogram
    
- Trapping Rain Water
    
- Sum of Subarray Minimums
    

High-frequency interview territory.

---

## ğŸš€ Final Structural Takeaway

Monotonic stack works because:

- Traversal is one-directional.
    
- Decisions are irreversible.
    
- Each element participates in â‰¤ 2 stack events.
    

That guarantees linear time.

---

# ğŸ§© Submodule 2.1.2 â€” Span & Distance Formulation

---

## ğŸŸ¢ 1. Mental Model

2.1.1 was about:

> â€œWhat is the next greater value?â€

2.1.2 shifts to:

> â€œHow far does dominance extend?â€

This is not about finding a single next element.

It is about measuring a **range of influence**.

Example mental shift:

Instead of:

- â€œWho is my next greater?â€
    

Think:

- â€œHow long can I survive before someone stronger appears?â€
    

This is distance thinking.  
Not mapping thinking.

---

## ğŸ”µ 2. Why This Exists

In many problems:

- You donâ€™t just need the next greater element.
    
- You need how many elements you dominate.
    
- Or how far you can extend before being stopped.
    

Brute force:

For each element:

- Walk left or right until blocked.
    

Time = O(nÂ²)

Monotonic stack turns this into:

Time = O(n)

Because each element enters and leaves once.

---

## ğŸŸ£ 3. Core Building Blocks

This submodule introduces:

### 1ï¸âƒ£ Index-based stack (mandatory)

Distance requires:

```
distance = i - previous_index
```

Values alone are useless.

---

### 2ï¸âƒ£ Direction matters

Span problems often require:

- Scan left â†’ compute previous greater
    
- Or scan right â†’ compute next greater
    

You must choose direction based on:

- What the question measures
    

---

### 3ï¸âƒ£ Strict vs Non-Strict Comparison

Critical detail:

- `>` vs `>=`
    
- `<` vs `<=`
    

This changes span behavior.

Example:  
Duplicates behave differently depending on comparison.

This is not cosmetic.  
It affects correctness.

---

## ğŸ§ª 4. How It Behaves in the Wild

Common span-style problems:

- Stock Span
    
- Largest Rectangle in Histogram
    
- Sum of Subarray Minimums
    
- Previous Smaller Element
    

All follow this structure:

1. Maintain monotonic invariant
    
2. When popping:
    
    - Calculate span or contribution
        
3. Push index
    

---

## ğŸ› ï¸ 5. Real-World Usage Patterns

This pattern models:

- Influence range
    
- Dominance window
    
- Valid interval expansion
    

In production systems, this appears in:

- Time-series peak detection
    
- Window-based anomaly detection
    
- Trend duration tracking
    

The stack is just a device.

The real concept is:

> Dominance propagation until blocked.

---
# ğŸ§  UNIT 2.1.2 â€” Span & Distance Formulation

## Structured Q&A Session (Encapsulated)

---

## â“ Q1 â€” What exactly is â€œSpanâ€ measuring?

**Answer**

Span measures:

> How far an element can extend before being blocked by a stronger constraint.

It is not about:

- Finding the next element
    
- Mapping value â†’ value
    

It is about:

> Measuring the uninterrupted region where a condition holds.

In Stock Span:

- Condition = previous prices â‰¤ today
    
- Blocker = previous price > today
    

Span ends at the first blocker.

---

## â“ Q2 â€” Why do we use indices instead of values?

**Answer**

Because span is distance-based.

We need:

```
distance = current_index - previous_blocker_index
```

Values alone cannot compute distance.

Indices give:

- Value lookup
    
- Unique identity
    
- Direct distance computation
    

Span problems are index-driven.

---

## â“ Q3 â€” Why does the comparison operator matter so much?

**Answer**

Because the operator defines:

> What is considered a blocker.

If problem says:

â€œprevious days with price â‰¤ todayâ€

Then blocker is:

price > today

So equal prices must not block.

Hence we pop while:

```
price[stack.top] <= current
```

The operator encodes the boundary rule.

It is not arbitrary.

---

## â“ Q4 â€” Why does each element enter and leave the stack only once?

**Answer**

Because:

- We scan in one direction.
    
- Once popped, an index is resolved permanently.
    
- It never re-enters.
    

This creates an irreversible elimination system.

Total operations:

- â‰¤ n pushes
    
- â‰¤ n pops
    

Time = O(n)

---

## â“ Q5 â€” What breaks O(n) in span problems?

**Answer**

If you:

- Revisit indices
    
- Reinsert popped elements
    
- Scan backward repeatedly
    

You destroy irreversibility.

Monotonic stack works because:

> No element is reconsidered after being resolved.

---

## â“ Q6 â€” Why do equal elements sometimes need to be merged?

**Answer**

Because in many span problems:

Equal values do not block each other.

Example:

```
80 80 80
```

Each 80 should absorb previous 80.

If you treat equal as blocker:

You fragment the span incorrectly.

Thatâ€™s why operator changes per problem.

---

## â“ Q7 â€” How is this different from 2.1.1 (Next Greater)?

**Answer**

2.1.1:

- We stored value â†’ next greater.
    
- Output was mapping.
    

2.1.2:

- We measure distance or width.
    
- Output depends on index spacing.
    

Both use monotonic stack.

But the abstraction is different:

- 2.1.1 â†’ Deferred resolution of value.
    
- 2.1.2 â†’ Dominance range measurement.
    

---

## â“ Q8 â€” What mental mistake causes confusion in 2.1.2?

**Answer**

Treating it as:

â€œJust another next greater element.â€

Instead of:

â€œHow long does this element dominate?â€

Span problems are about influence zones.

Not about one-to-one mapping.

---

## â“ Q9 â€” When do we choose `<`, `<=`, `>`, `>=`?

**Answer**

Ask:

> What exactly blocks extension?

- If equal should merge â†’ pop equals.
    
- If equal should block â†’ keep equals.
    

Operator reflects blocker definition.

Never copy it from another problem.

Derive it from boundary rule.

---

## â“ Q10 â€” What is the invariant of 2.1.2?

**Answer**

The stack always stores:

Indices of elements that have not yet found their blocker.

And maintains monotonic order such that:

- The nearest stronger blocker is always accessible at top.
    

This guarantees correct span calculation.

---
